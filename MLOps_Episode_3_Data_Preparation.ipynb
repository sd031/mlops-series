{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "419d578d",
   "metadata": {},
   "source": [
    "# MLOps Episode 3: Data Extraction, Validation & Preparation\n",
    "\n",
    "In this episode, we focus on three critical steps of data preparation for machine learning models:\n",
    "\n",
    "1. **Data Extraction**: Retrieving data from various sources.\n",
    "2. **Data Validation**: Ensuring data quality and integrity.\n",
    "3. **Data Preparation**: Transforming the data for analysis.\n",
    "\n",
    "These steps are essential for ensuring the data used in machine learning pipelines is accurate, relevant, and ready for analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8ce049",
   "metadata": {},
   "source": [
    "## Data Extraction\n",
    "\n",
    "Data extraction involves retrieving data from sources such as databases, APIs, flat files, or web scraping. Important considerations include:\n",
    "\n",
    "- **Source Identification**: Determine where the data resides.\n",
    "- **Data Formats**: Understand formats (CSV, JSON, XML, etc.).\n",
    "- **Automation**: Use scripts to streamline the process.\n",
    "\n",
    "### Sample Data\n",
    "We'll start with a simple CSV file:\n",
    "\n",
    "```csv\n",
    "user_id,name,email,age\n",
    "1,John Doe,john.doe@example.com,28\n",
    "2,Jane Smith,jane.smith@example.com,34\n",
    "3,Sam Johnson,sam.johnson@example.com,22\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b137642e-46fb-49f1-ab5a-b4a23e74fbfc",
   "metadata": {},
   "source": [
    "Install Dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7376dc92-9d64-41b5-892b-b2f4f474ebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcd6596a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John Doe</td>\n",
       "      <td>john.doe@example.com</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jane Smith</td>\n",
       "      <td>jane.smith@example.com</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Sam Johnson</td>\n",
       "      <td>sam.johnson@example.com</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id         name                    email  age\n",
       "0        1     John Doe     john.doe@example.com   28\n",
       "1        2   Jane Smith   jane.smith@example.com   34\n",
       "2        3  Sam Johnson  sam.johnson@example.com   22"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load CSV data\n",
    "data = pd.DataFrame({\n",
    "    'user_id': [1, 2, 3],\n",
    "    'name': ['John Doe', 'Jane Smith', 'Sam Johnson'],\n",
    "    'email': ['john.doe@example.com', 'jane.smith@example.com', 'sam.johnson@example.com'],\n",
    "    'age': [28, 34, 22]\n",
    "})\n",
    "\n",
    "# Display extracted data\n",
    "print(\"Extracted Data:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8bae1a",
   "metadata": {},
   "source": [
    "## Data Validation\n",
    "\n",
    "After extraction, validating the data ensures quality and consistency. Important steps include:\n",
    "\n",
    "- **Schema Validation**: Ensure proper data types.\n",
    "- **Missing Values**: Handle missing entries.\n",
    "- **Outlier Detection**: Detect and manage outliers.\n",
    "- **Consistency Checks**: Ensure consistency across sources.\n",
    "\n",
    "### Sample Data with Issues\n",
    "\n",
    "```csv\n",
    "user_id,name,email,age\n",
    "1,John Doe,john.doe@example.com,28\n",
    "2,Jane Smith,jane.smith@example.com,\n",
    "3,Sam Johnson,,22\n",
    "4,Emily Davis,emily.davis@example.com,120\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6570af9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Introducing issues in data\n",
    "data_with_issues = pd.DataFrame({\n",
    "    'user_id': [1, 2, 3, 4, 4],\n",
    "    'name': ['John Doe', 'Jane Smith', 'Sam Johnson', 'Emily Davis', 'Emily Davis'],\n",
    "    'email': ['john.doe@example.com', 'jane.smith@example.com', None, 'emily.davis@example.com', 'emily.davis@example.com'],\n",
    "    'age': [28, None, 22, 120, 120]\n",
    "})\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = data_with_issues.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)\n",
    "\n",
    "# Outlier detection\n",
    "outliers = data_with_issues[(data_with_issues['age'] > 100) | (data_with_issues['age'] < 0)]\n",
    "print(\"Outliers:\\n\", outliers)\n",
    "\n",
    "# Basic schema validation\n",
    "print(\"Data Types:\\n\", data_with_issues.dtypes)\n",
    "\n",
    "# Duplication validation\n",
    "duplicates = data_with_issues[data_with_issues.duplicated(keep=False)]\n",
    "if not duplicates.empty:\n",
    "    print(\"Duplicate Records:\\n\", duplicates)\n",
    "else:\n",
    "    print(\"No duplicate records found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726e534e",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "This phase transforms validated data for analysis:\n",
    "\n",
    "- **Data Cleaning**: Remove duplicates and handle errors.\n",
    "- **Feature Engineering**: Create or adjust features for better model performance.\n",
    "- **Normalization and Scaling**: Adjust data for better convergence.\n",
    "- **Splitting the Data**: Create training, validation, and testing datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163ac97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Introducing issues in data\n",
    "data_with_issues = pd.DataFrame({\n",
    "    'user_id': [1, 2, 3, 4, 4],  # Added a duplicate for testing\n",
    "    'name': ['John Doe', 'Jane Smith', 'Sam Johnson', 'Emily Davis', 'Emily Davis'],\n",
    "    'email': ['john.doe@example.com', 'jane.smith@example.com', None, 'emily.davis@example.com', 'emily.davis@example.com'],\n",
    "    'age': [28, None, 22, 120, 120]\n",
    "})\n",
    "\n",
    "# Checking for duplicates before removal\n",
    "duplicates = data_with_issues[data_with_issues.duplicated(keep=False)]\n",
    "if not duplicates.empty:\n",
    "    print(\"Duplicate Records Found:\\n\", duplicates)\n",
    "else:\n",
    "    print(\"No duplicate records found.\")\n",
    "\n",
    "# Cleaning data: Remove duplicates and fill missing values\n",
    "data_cleaned = data_with_issues.drop_duplicates()\n",
    "print(\"\\nData after removing duplicates:\\n\", data_cleaned)\n",
    "\n",
    "# Filling missing age values with the median\n",
    "data_cleaned['age'].fillna(data_cleaned['age'].median(), inplace=True)\n",
    "\n",
    "# Normalize the age feature\n",
    "scaler = MinMaxScaler()\n",
    "data_cleaned['age_scaled'] = scaler.fit_transform(data_cleaned[['age']])\n",
    "\n",
    "# Splitting data into train and test sets\n",
    "train, test = train_test_split(data_cleaned, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"\\nTraining Data:\")\n",
    "print(train)\n",
    "print(\"\\nTesting Data:\")\n",
    "print(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc2312e-8187-4c35-90dc-033778863a99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
